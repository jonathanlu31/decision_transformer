{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "siq9NH6h_71v"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gym\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm.auto import tqdm\n",
    "from decision_transformer import DecisionTransformer\n",
    "from training import Trainer\n",
    "from dataset.trajectory_dataset import TrajectoryDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "wandb.init(project='decision-transformer')\n",
    "wandb.run.name = 'gpt2-colab-full-clen-20-lr-1e-4'\n",
    "wandb.config = {\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"epochs\": 500,\n",
    "    \"batch_size\": 64,\n",
    "    \"hidden_size\": 64,\n",
    "    \"c_len\": 20,\n",
    "    \"device\": \"auto\",\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"betas\": (0.9, 0.999),\n",
    "    \"activation_function\": \"relu\",\n",
    "    'dropout': 0.1,\n",
    "    \"warmup_steps\": 10000,\n",
    "    \"num_workers\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 327482,
     "status": "ok",
     "timestamp": 1668119058242,
     "user": {
      "displayName": "Jonathan Lu",
      "userId": "10961139188022815070"
     },
     "user_tz": 480
    },
    "id": "RjzaU5NO_710",
    "outputId": "36d8fc29-28c3-4960-a606-5f15ffd9862f"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"epochs\": 500,\n",
    "    \"batch_size\": 64,\n",
    "    \"hidden_size\": 64,\n",
    "    \"c_len\": 20,\n",
    "    \"device\": \"auto\",\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"betas\": (0.9, 0.999),\n",
    "    \"activation_function\": \"relu\",\n",
    "    'dropout': 0.1,\n",
    "    \"warmup_steps\": 10000,\n",
    "    \"num_workers\": 0\n",
    "}\n",
    "env = gym.make('CartPole-v1')\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "c_len = config[\"c_len\"]\n",
    "\n",
    "# train_dataset = TrajectoryDataset('dataset', c_len, state_dim, action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "eb494f5633784c8d9aa39de98ed9a033",
      "070da1212c78495887d7776f8e4c6f6f",
      "6276dd7a00c04bee91e4d4b24ca3a05b",
      "dfef26e9f07c48eab6b2979fa36cb917",
      "858e9e70d1104dac937a00729b7ac033",
      "b3e80263b4514065b1621e51171058d0",
      "02311a2038ed4f259a2c618445917890",
      "e89a5300efa84601a8e5a2a43ea4a70c",
      "080b4eb3dd5e45fb8c3675f8a02ed188",
      "147f6f0dc5f746e6b8e7b38fe04ef905",
      "fdf1300148954edc914dc90fc9bc784f",
      "34d27ffbb1424553bc4cac41e26d0fe9",
      "2bf1982cd295403ba5848fe64867887a",
      "f9ea6355c9724c5c9f707ff0a7cab8b9",
      "d2581e44570b411a8811d717453539b2",
      "5709e0020fdf4cf3a6957109defa151f",
      "e090f243979a4ed1aa030da629b6edff",
      "52ad745e2de044339d8a72fdb68fe194",
      "5f00b03c7ba049c18bf122552fd2ab52",
      "ab976409956c40fea76a293a26c7c611",
      "3f2b8841214f4510a467d374d619a3fc",
      "d791d0ae4828458897b71f74740af3d7",
      "89cfc2fb0a8343fd9c5f44cc611adf96",
      "6d301315d59e45dca99a71080bd8b45a",
      "97a2945d4d8b43ee8961540ca9d6be6f",
      "7ffd60c44fd94a338470f71947c7276a",
      "150e9e569b4d4fb586843ae96681dc89",
      "d1edd2c90c354ba5b1a4bba359c20477",
      "4b25d604201842e5a7bb9bc2550416a5",
      "a8cc167878f74c6ea1e30fd30bf558e5",
      "c9d504c0607e46708a45570d4c44db7a",
      "3b453f903c094be2814351fafced3a7f",
      "00918a8d76d941479896350a658b005a",
      "9f22862b36ab45918cf0b3e3ae541a90",
      "20e5ffcd4a4240f09fd64b923034d19e",
      "ebf8df2815ef4f529737c49b7ca9ddbb",
      "ee3d1fe6e3b8448c8a60d0e5c6710dc0",
      "60b4e79ab2d94c08abdd4e125524f2ea",
      "cf506596822e4df4a04b874b6aa5d9e1",
      "ed5c54c5c13b4f56ae0fe4f07989cc4f",
      "5c44100c62ea45f384d8cf29bf1f1b46",
      "6487098ac4a0406eaa6861cbaf471318",
      "9c6fdf580b8e4d6eba4786477a4a2c7a",
      "bfed1097e05a4659bf5537546a9a95b1",
      "74279d3c899d4c64ba96a1d093f9a79c",
      "b7f8f905e4db4382a623ced54b5d3bf5",
      "055d687ee68241a8964f07cd026846db",
      "8e947399be16431f9e12c193c27ea751",
      "e75aa783a39f4bb4a1bb10ca4f558953",
      "1114d918afb94e509fae8cd473b01d55",
      "da64515400da413a8badc695dee111a4",
      "7635806662124b97a0e1b0cb792d39c1",
      "28b9041f68d5442f8d6cd34fa431d045",
      "3f5bd052eacc493dae228ec631da9f66",
      "28b6281dc8f040a386f815ef8b682d9f",
      "6a58ace8027644e695cbb231d2b13031",
      "98660a4d8d2c4526899ddb83b38bb869",
      "41b4109417b4497ba466b468c23e81b2",
      "28a936d7b70f4b05a875fdd2a6b55f70",
      "bed6378927134e2089b6bce52fb39930",
      "5bc06823952f44d496e64fff3a6e7028",
      "73012ca4c68d4b728fadcbc908d27ccc",
      "86791235327c430db8dec850d4282dba",
      "115b48cdac11449889d3d4b98d4fc2b4",
      "f55439c702394b71ae3931b1dce2c5c2",
      "f6b0632704634dc9b8aba31102b2baee",
      "81288efb69b6421cb3b7b40a7ac38088",
      "9bbdcc734b0042d38d86e311bf59524a",
      "327b045e686844cb959b4235e475097e",
      "39ca7b9480f342908a8a297820c16ac6",
      "fd0bfc79f28346b787bbfb3c36a89fe9",
      "ae36027c838344a2887859bd89c1045a",
      "085febd535fa4a08883abcf07d0c0fbb",
      "8f0f4189d7ba4fe59bddebfa7a802982",
      "c33294a790c24890846d8c15ede22bc6",
      "77193a5c858e4b908278f2aff9e03f81",
      "2c68b00346e645be864d760bd433d95a",
      "814b781978a54beeb45c9a857aadf2d5",
      "564141396329457c8fa5002c3bd99bbd",
      "63242e0269264a39a30818d7ff33c50f",
      "f508940f56714810bec72f87d9350848",
      "5e49977f6e554e749063ed5bc1c15914",
      "f4641a9192cc4df2a60f5b388f4b4b37",
      "33212649bd3142c89061ae735c65c1ed",
      "da641f098c2743a38c020e6fedbe4b64",
      "b7faa2101c75465fb02e44fde6da39cc",
      "462ca3c7c8504889beca61613097d7ec",
      "e0e2f39b5217424099f5857e82d52b99",
      "05c07f621a644ca78b0d9d737939076c",
      "84e7c5f1f3aa4c05bf606e759f2b4ba2",
      "e1c01682c18d49b88ac7baa622c55b1d",
      "ad87d3e3dc1f41cdafcc72c34d0ea3ad",
      "5b221235b7434af98e725897055431d8",
      "9ead4b3dcb63400488e21fba49100b0c",
      "12b3630fb7ec46b0932d9a287769769d",
      "2d3db1411e434115b6160f28b9871d60",
      "5c46b31757ed4116a5b70bd3cb292839",
      "88aa9e75ad7d4a1abd8189268b531298",
      "61ecae04082347a7a7f86b226accb453",
      "3dc60aca9e8c48a083a6440d477a9270",
      "e690b5f7eecf451da2adcb0a9c3ff1cf",
      "968890011a7c4ac98b051a5d7e29c8ee",
      "8f51aea4876342f29ec70aca00efe155",
      "637385646703417184ebe8019754c578",
      "c5da8297dd414e1ab2d7fc9c0ef7b4d9",
      "a36ca257e3434c008381b7d3f0e2df3e",
      "30a87d5849ac47bf95421c3f4c2c6e1b",
      "0806271216dd4ac8b1a9b06f3e9d9d1a",
      "4edad1a1a3dc4cbb8bbd51b27649b792",
      "ec023139c4cc4eb69f865470bf1a0cc1",
      "cc0e4c76b7fe4d6dac1d1efcce426d7e",
      "1218a9dd66f74fdbad5d8a498723ee41",
      "e352f3e5d8dc4f75b38c0533d3741214",
      "9dfe141c61274023bbef5449e5a79012",
      "1dc5330064c84a9fbf39753bd4742105",
      "5ebfa6e4f51c4a999319a27c5ff39937",
      "819b05b720154c15b163dc75a8b48f27",
      "985b12787c0c4f3f8fa0eca2a65efe70",
      "a0506a15523645789a2cc4288f0c861c",
      "d837dc4c770f4a25aa57fbcfecee0b99",
      "fca6f8d8e8c34da283b6f840c26c9105",
      "4ba4097e6a4f499eb780e580bf4629a9",
      "b329f2f0e2a24caa9bde31135351f974",
      "79b26469d11e40c09e6a2322316394d5",
      "e9311cda97b8412eabba2a00f5109918",
      "9eab06a8b8d949ed854dfe5bbbf841ec",
      "1d221c2618034898bf4c9c195139de4a",
      "9e5c7566cd1f48378310c5cf3e8d8400",
      "c489945319dc484f8298a1a874bf8235",
      "1871f8dd1b20451685b1446c44df100d",
      "455f2f0841c24de5afdee5a2031ae773",
      "6541f28ad897434bb564bf27f16c9195",
      "bdc939534d724ee187a9ac1e434c19b0",
      "abcbeab904a148d58de9987d632a5117",
      "c5583bd80cb549feb31de52a4612ceca",
      "6d583d7e23b94b2e96720d821ae5f296",
      "773bf86d9939497593134e9e5dcef0b7",
      "f4894ef42ffd465e9f9dfff8c6cb9fd5",
      "c95eab6480814ff2ae1cbc2f1b7620b7",
      "f62b3a5db47447698814fd5cd9257bd7",
      "dce29c62d95a4a98a6c44413c73bb118",
      "ad1a6baa0fbe485591872e3b19c3657e",
      "e1a5d2db514d41a3a39e37b66d8423dd",
      "cf6bad007dc044709edd6d5ca570b5a5",
      "755169875ce7495bbc12a7328edf2ecb",
      "d997e78eccf3487fa59e439bb2823e9c",
      "cdbe59452f1b49a1a0a39526292d672d",
      "922bcf516a5b4035a7afa805a1a91586",
      "4b786c4b485a4c2f85a3c4b21492deb0",
      "05410f9973ed40e48f7df3e90595c9e4",
      "6c1c3b3152694c1bb56006c47c553a76",
      "2594065982ab4e9a81230d6ece24e029",
      "53c4d5bb779b4d7193dc5dab8c963070",
      "fa108a1a974d4d3cb770dfccf72d6ba3",
      "889ec6c121b242c79588e86c7da71f79",
      "60fb72f2bc4e4e52ac3a0840e99c391a",
      "7781f52b2e5c47f78988bf938406cebf",
      "aaabfc8ce0084ecfa43b6889dc8ac469",
      "cdb950b86aed4b128b516a8070e35c85",
      "dd8a416d2d8e4276a179ae22a8ddc3bb",
      "10d73be99e1148a1af3571c7036fef57",
      "6f9d5cec130e412a9012f152d52572c4",
      "5537f33a71a14c58ba469d6603798284",
      "6546c68992a74586a30595954a64b1f4",
      "befab71e81e54b2dad12eef1772577e3",
      "1fd3fbde35e849ea959dc1be0ca40551",
      "c456958677064bea8abdac4360564924",
      "64646e0dedd5426390682dc018a09c46",
      "b31d1e4a0cdd498faad29c7b9e1f1678",
      "ad6ef11625034b81b50dcc48ccf4a8ad",
      "08454c1f0b2d4e23afe1f818a732e258",
      "ed433fa0386b4e9284877e6cb3315007",
      "152636487542440c99ef705eb5ddebae",
      "ad0c7b4d296f4893ba522788fd34948d",
      "4b3b56adad0a4e3496e7ba126e5ec1cf",
      "aba9866ff9c5420facfa5b25d7314fd0",
      "2faf11f2644a4ab19e6a09959147e8d6",
      "360f0d59581e48e98e39c56f0256e9bc",
      "13c1fbcbf5fe48c5a310826d2af02527",
      "7366a4bf2b544a849bd7904509ddc8cc",
      "46623b78e5bb46b79dbecd840bc2da3a",
      "fb819f10bf274469b66b2231f8a625ec",
      "f3eb6d8676db4ecdb93e05756de4a09e",
      "6d583f2ca41b4e7d96bb7b31f644724a",
      "8cef2bea84bc4915989d0c4ee3d6b644",
      "9406469dd6fa48bcb84a5bb4c3e22b6a",
      "a7ec425b024c40a599a086f056d93921",
      "ca3fb6265424470c959885fe7137b924",
      "4473f40155c64e2b9a018f30981dfbd4",
      "dfc0a4161af148fca3a799df423cfe47",
      "79252f8c963940f5837f64f98bbd5798",
      "73cce71aad6d46ac9522705ee68f66d7",
      "ec85aeac6eea495ebfeac0190e0c1363",
      "9cd1c30af22b4c6c88bf63b0c7768bc6",
      "d003e3021f9d4707a7bf2831bbc44f02",
      "a7c3c3fd4ae046a182d7f893ac43f7da",
      "8d56a1a934ba436fb37ae084f5e03a0a",
      "6c6e2330366b47358f22e05a679e1fe9",
      "7c2d882a638149c8a0fcf5ababd829c9",
      "1d16a8bbc7804709aa287ed8af8c3154",
      "b158f1f3f42d41ed8253a0d8ad45597d",
      "6aa9320786ef4d279ffc0f7de02c5ee0",
      "5872845580424d83a16bbdb960804002",
      "5d03647aed034aaf88b640e9644f0c98",
      "0ef3c2bbca614436b554df431d7e9d5b",
      "26f05b225f3f43c2bde2198a66cb1b5c",
      "a0f1e341827940c3aa189b4244d0d19e",
      "6f99fcca94bc4e52974e27fdd30fcc15",
      "9be17f95e227424caf1d1a88a13b4c22",
      "de39d6fc00ba4117a503e764347e5168",
      "56b4c7b41a964d919410bb2f8b5194fd",
      "3f53caaaae3c4f3299504115fb055cbc",
      "19c42852d3c944b18496dbd10b7e4754",
      "4140d0d83de4467c8eb4d327be80122a",
      "f9345980eaeb46ecb8ac959c55505191",
      "52eaf32a951342beaf7054860c0f001a",
      "af5330a7630b4b0ca6643781d6416745",
      "3fc3afcf7d594bafab1eb6048046b6e3",
      "0b66f9a84c5541faba36b60e9aeeb57c",
      "238caf19998a41da94e74d99881785a9",
      "4087c74898634e59850620013065fd1b",
      "80a2a78db8c04bde8dc15f1374f9ef91",
      "0a9efb02372f49698c7b236b6360839d",
      "5a5a29346c5e4d76bf2a1b96a40f1fe6",
      "bce92018ec5e4d24901e493277ad2737",
      "490472119ba443519c87808338e1ac4c",
      "e2f8bb77c1ca4cc88cc4d07b45272adb",
      "4c460ee9f2d14705a0b71e4a1902e9b6",
      "f338e816c0c145fdb69948c7a545135e",
      "55bf1cc47b454224bbce2a4a3e9e4e02",
      "033527a45840421bb60033ac589ff2dd",
      "1c076f8cc38b4d0cba03e9227d7f1543",
      "c8d0d62524134dbfac777d2d6752a56a",
      "ae70938762ed4e7da88d35bd73a2bb49",
      "a54a9188ed4042cebf7d7a78a43f5498",
      "73a6383379604f1c84e1f8a2f1361934",
      "0b591b30c2c742cfadeb8e1dd483b9d5",
      "032e517c54e1482c81afab0461385576",
      "3b12858d16e44737a38a4946ffb06cc8",
      "0c82e925ea734a43aa0efd5262c2bd1e",
      "ed6a6a0533654661bf2912b0d2b26248",
      "4d6eb7cf1886468b8dec4b2a6fd7c87c",
      "9fede70b1e8047a5aae245267710b191",
      "0609c302d8914d7a967930aa5f9fedf8",
      "bfb016728e7348968e13850640ebce1d",
      "016cb2b3ec714057a963d752c46a2f08",
      "1cc9553824c543d0b56532ce45969f60",
      "35f0b372481c48ba977c7a868e8a241c",
      "1b2ec684e33f4b579b1de87ceec409e8",
      "1cd279edd60f46d394ca66c10407120c",
      "e45b803be88543c9b56bd7ebc713cdd2",
      "81fc514161604a74b07c7df1eef3f7a2",
      "4bed44d1e2a446a6bb995150755deb11",
      "7746b3528c304ca0baf7b6bfc53fddc5",
      "7557ebdf8cb549478166f21507ae17e3",
      "ec5b7f310cf640d7845cbc5498706510",
      "fffb665b3d0441d1a8d9b6fcfe0ded19",
      "851828c5ddd342f089ecceb0c6c83556",
      "1f45f8bc11ad49598f94aa0462531d27",
      "f2881a21c46647b3b4db0ecba68cb97d",
      "51ef70a289354978a1328dcf49d6149f",
      "6916a26851a74266becc34eaed8024bb",
      "49dfc83700834350b48de7461fa91979",
      "8814ee0754484e01ad200eeacc6faecb",
      "5c2e369d8130475192db3839c018621b",
      "b4949a8ac5974f1f93927a39073b86e4",
      "246fa80baa3c40299ad1ee4bd0ee6405",
      "e9a6be197bbf4d05a117d1f8880a6f11",
      "f2675d3373d743109f733969254fc8a0",
      "c23c624be1ea46068bb7cfa300ae29cf",
      "39b896013e944a478d4d49a9d813810f",
      "04e484f946c747bdb83908cf1fc17b91",
      "a2d708cf642142b084419921c9382a22",
      "8d7ef5e4fa6444a2b06121d10e6b4541",
      "fdf89a8d9ac041598597108f1d5b79a4",
      "9d421c44310745629b0a18cefe5a23ae",
      "f2c39de08cfb493a825948d881ff118b",
      "5dd0f29864d14d14b0fd0a3c044757d7",
      "0b1cfefae9494dd4b484e6e198fe3f01",
      "2ce7ae327f6c48b4811b8e913fb2fe39",
      "af7955021f13488e80bc46018330132a",
      "c7bf17d006234519bc2fb6250eae322d",
      "94bab6a3e7404e0992eafd08818a77b8",
      "7087a947762d481d90aad92bf06dabc9",
      "cc07bd45160044dbab2651970d5ab043",
      "1ed3e6cb2048465aa9296aef319934d6",
      "99e79d1cfd1447698828fa71f5ab9946",
      "dc89aedc08eb4863ba8962b9ca973b5f",
      "65d047633a0b4b048bf1e5a54857c654",
      "c0cebfd9137641cfa76cb546eba69fe0",
      "b3b79be6ef2e401cb9b3140cbd21c872",
      "3dfbe60a10be46319d1b5a1aa3bdc3ca",
      "5682bf2b074345f39156ae4c7d22b122",
      "9a5cb2d5a64740f29761764fcf586f22",
      "2acd29bd03b84aefa14405f239527b72",
      "39c2fb884a364e7db7e9019f3e9ae5e7",
      "27ed7d73a6e84cb58f61f358309c2a22",
      "c99fb11806f24671a2fa143f98ccfa9a",
      "d46902423a92415aa23d93775c039e08",
      "c1564015717d4d57a9405adde9f1fbc0",
      "095c0ce93140403a9b6ec97ba6c42c6d",
      "01ceb0cee40645af977279f0256a5354",
      "0e9893173c7a4b3db101b897ba31fc10",
      "a0873f4b004046758ad1f50383b709a0",
      "7742df332b2d42a798ca1fcbfa7bdb84",
      "0c31220bc95f4f94826317b7f69e4c12",
      "90d40d44877b4202806e0f436bdb185d",
      "6bc95aca1f9e4cfa9a5674c34b0c42c8",
      "5d63b6ff6cd04317b1391ce20beb7982",
      "df74a42280004d81b1ad14c6581e28d5",
      "797a0810948a44ce9ff35cc482567507",
      "b02fc28d09a2428693daf99ccb3f9eca",
      "2f0337150e354299b9142c60cee54fff",
      "54a9e07ce6ca490a95d431011a15b861",
      "ad260027191142a997fdbbcfc8ef8c4d",
      "3de28f4915904028bc31a1ea4d9abe97",
      "b616e9bcce054993b2faa3a4028ac930",
      "ed9d07c38b674367aa13d668a6852cf0",
      "1e526f819a074914ad6c798ac6060557",
      "a846b506a99245c0b57cb0cebbf7ac29",
      "7d17509670a14923a230db78b2d7fd64",
      "f2e4d461a2974c44909d1d8f769b7ecb",
      "6dad9ff4513a42e4aa8694712a83c7f8",
      "859f970596be4282b72f1f5897264780",
      "c2106f42b6704f7fb8a4a31f719c61d5",
      "49ac8e67cac045298dbebb8a79d1e37f",
      "3a50adcb7f9445fbab0368466a3b36df",
      "1657eb9a9a984b709cd75234817b7970",
      "e2a5c4285f6d41b2b825647b771a3583",
      "eed7822fc09a47be965a02fe248da869",
      "2e1d471c87c64580a6b7b9745cdbde54",
      "1e197a73e6414a58880057079a71377d",
      "f79d827d9f454804891af298b12faae0",
      "096b9da4309c4596be1afdb4f5a55d8e",
      "e42759eecc4f4bea91b8d9613f6897f8",
      "f7436f63afcf4aaa89d9ba1f143332d1",
      "ecdb1fcaa6364d0594cf0ee0d426211e",
      "d8a567da120748fe9ce176cf8f796240",
      "9d5438a86b39482d9386b8c9f6a06aa1",
      "c7e275c028074456b46f552251652f30",
      "def44f13af8d4f8ca2e32cd7e70078e0",
      "896a809653a1413a8512baa07055174d",
      "0a38e9047eeb466da6e20ed8f13dc452",
      "0518daff19554a9bbf71b9abe9a54410",
      "9830eba29be14ffca11deb9eebae3103",
      "5bc565431005458c843f888a3ed889ab",
      "069b9d54831249c7a4350d8346e36544",
      "c7267fb0a26a4818976b675d6059d6e0",
      "9cdeb897dd8640e2824a39b7bba107cd",
      "f8ed0cd7df684160b0612d38413bb0af",
      "f7d67fdb649347b78975b4734be3b847",
      "090c62c21c694fcc8b28b55ae655da30",
      "2fe709e4570343b98aeee6ee0a09f56b",
      "75d24a6a92b44e55aa9e063007fc003b",
      "e71001700bce44f4b8d3e4281931067a",
      "37d84da17bc644dca1710f37bc77718b",
      "7aea831da9794a8695f2faeeaf8af7aa",
      "f5dcb21042124e7f931ff79a357dc0d2",
      "b3b4597a75764ed7901d7adc63c6d8e1",
      "24f84280953148b68e4630f8e07a654e",
      "0cfdb41d39ce4ab0b0c29589c4d216d4"
     ]
    },
    "id": "7Kg7olYa_712",
    "outputId": "35162e44-ff1d-4c01-acc1-87e58e1740e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 1\n",
      "64 1\n",
      "64 1\n",
      "number of parameters: 0.15M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathanlu/dt-all/dt-all/decisiontransformer/minGPT/transformer.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask = torch.tensor(mask).view(1, 1, actual_seq_len, actual_seq_len)\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTransformer(state_dim, action_dim, config[\"hidden_size\"], c_len, 200, True, n_head=1, n_layer=3, n_inner=4*config['hidden_size'],\n",
    "            activation_function=config['activation_function'],\n",
    "            n_positions=1024,\n",
    "            resid_pdrop=config['dropout'],\n",
    "            attn_pdrop=config['dropout'], device=config[\"device\"])\n",
    "# trainer = Trainer(config, model, train_dataset, loss_fn=lambda a_hat, a: torch.mean((a_hat - a)**2))\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTransformer(\n",
      "  (transformer): minGPT(\n",
      "    (transformer): ModuleDict(\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "      (h): ModuleList(\n",
      "        (0): Block(\n",
      "          (ln_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): CausalSelfAttention(\n",
      "            (c_attn): Linear(in_features=64, out_features=192, bias=True)\n",
      "            (c_proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ln_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): ModuleDict(\n",
      "            (c_fc): Linear(in_features=64, out_features=256, bias=True)\n",
      "            (c_proj): Linear(in_features=256, out_features=64, bias=True)\n",
      "            (act): NewGELU()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): Block(\n",
      "          (ln_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): CausalSelfAttention(\n",
      "            (c_attn): Linear(in_features=64, out_features=192, bias=True)\n",
      "            (c_proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ln_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): ModuleDict(\n",
      "            (c_fc): Linear(in_features=64, out_features=256, bias=True)\n",
      "            (c_proj): Linear(in_features=256, out_features=64, bias=True)\n",
      "            (act): NewGELU()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): Block(\n",
      "          (ln_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): CausalSelfAttention(\n",
      "            (c_attn): Linear(in_features=64, out_features=192, bias=True)\n",
      "            (c_proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ln_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): ModuleDict(\n",
      "            (c_fc): Linear(in_features=64, out_features=256, bias=True)\n",
      "            (c_proj): Linear(in_features=256, out_features=64, bias=True)\n",
      "            (act): NewGELU()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (ln_f): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (embed_timestep): Embedding(200, 64)\n",
      "  (embed_return): Linear(in_features=1, out_features=64, bias=True)\n",
      "  (embed_state): Linear(in_features=4, out_features=64, bias=True)\n",
      "  (embed_action): Linear(in_features=2, out_features=64, bias=True)\n",
      "  (embed_ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (predict_action): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4tFBrL9_712"
   },
   "outputs": [],
   "source": [
    "# import training\n",
    "# importlib.reload(training)\n",
    "# import decision_transformer\n",
    "# import minGPT\n",
    "# from minGPT.transformer import minGPT\n",
    "# importlib.reload(decision_transformer)\n",
    "# importlib.reload(minGPT.transformer)\n",
    "# from training import Trainer\n",
    "# from decision_transformer import DecisionTransformer\n",
    "trainer.evaluate(env, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "esF2hwzf_714"
   },
   "outputs": [],
   "source": [
    "wandb.run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AI1xErH__715"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WY35W4jT_715"
   },
   "outputs": [],
   "source": [
    "plt.plot(trainer.train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o0Z-GTvS_716"
   },
   "outputs": [],
   "source": [
    "len(trainer.train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LdJExN7p_716"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1],\n",
       "         [4],\n",
       "         [7],\n",
       "         [2],\n",
       "         [5],\n",
       "         [8],\n",
       "         [3],\n",
       "         [6],\n",
       "         [9]],\n",
       "\n",
       "        [[1],\n",
       "         [4],\n",
       "         [7],\n",
       "         [2],\n",
       "         [5],\n",
       "         [8],\n",
       "         [3],\n",
       "         [6],\n",
       "         [9]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "return_embeddings = torch.from_numpy(np.array([[[1], [2], [3]], [[1], [2], [3]]]))\n",
    "state_embeddings = torch.from_numpy(np.array([[[4], [5], [6]], [[4], [5], [6]]]))\n",
    "action_embeddings = torch.from_numpy(np.array([[[7], [8], [9]], [[7], [8], [9]]]))\n",
    "torch.stack((\n",
    "    return_embeddings, state_embeddings, action_embeddings\n",
    "), dim=1).permute(0, 2, 1, 3).reshape(2, 3*3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdataset\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrajectory_dataset\u001b[39;00m \u001b[39mimport\u001b[39;00m TrajectoryDataset\n\u001b[0;32m----> 2\u001b[0m td \u001b[39m=\u001b[39m TrajectoryDataset(\u001b[39m'\u001b[39;49m\u001b[39mdataset\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m10\u001b[39;49m, \u001b[39m4\u001b[39;49m, \u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m~/dt-all/dt-all/decisiontransformer/dataset/trajectory_dataset.py:24\u001b[0m, in \u001b[0;36mTrajectoryDataset.__init__\u001b[0;34m(self, base_path, context_len, state_dim, action_dim)\u001b[0m\n\u001b[1;32m     22\u001b[0m path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(\u001b[39m__file__\u001b[39m)), \u001b[39m'\u001b[39m\u001b[39mtraj_dataset_good.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 24\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrajectories \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(f)\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mdone\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dt-env/lib/python3.10/site-packages/torch/storage.py:240\u001b[0m, in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_from_bytes\u001b[39m(b):\n\u001b[0;32m--> 240\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mload(io\u001b[39m.\u001b[39;49mBytesIO(b))\n",
      "File \u001b[0;32m~/miniconda3/envs/dt-env/lib/python3.10/site-packages/torch/serialization.py:795\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    794\u001b[0m         \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 795\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n",
      "File \u001b[0;32m~/miniconda3/envs/dt-env/lib/python3.10/site-packages/torch/serialization.py:1012\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1010\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1011\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1012\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1014\u001b[0m deserialized_storage_keys \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39mload(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1016\u001b[0m offset \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mtell() \u001b[39mif\u001b[39;00m f_should_read_directly \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dt-env/lib/python3.10/site-packages/torch/serialization.py:958\u001b[0m, in \u001b[0;36m_legacy_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    954\u001b[0m     obj\u001b[39m.\u001b[39m_torch_load_uninitialized \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    955\u001b[0m     \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m    956\u001b[0m     \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m    957\u001b[0m     deserialized_objects[root_key] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[0;32m--> 958\u001b[0m         wrap_storage\u001b[39m=\u001b[39mrestore_location(obj, location),\n\u001b[1;32m    959\u001b[0m         dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    961\u001b[0m typed_storage \u001b[39m=\u001b[39m deserialized_objects[root_key]\n\u001b[1;32m    962\u001b[0m \u001b[39mif\u001b[39;00m view_metadata \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dt-env/lib/python3.10/site-packages/torch/serialization.py:215\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 215\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    216\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/dt-env/lib/python3.10/site-packages/torch/serialization.py:182\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    181\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 182\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[1;32m    183\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    184\u001b[0m             \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m~/miniconda3/envs/dt-env/lib/python3.10/site-packages/torch/serialization.py:166\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    163\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    168\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    169\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    170\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    171\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "from dataset.trajectory_dataset import TrajectoryDataset\n",
    "td = TrajectoryDataset('dataset', 10, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "dt-env",
   "language": "python",
   "name": "dt-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Oct 24 2022, 16:07:47) [GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd8bb1db42cca79d7f3a48e5e66af8d98c691d61ba67f294729e1b2dcea446db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
