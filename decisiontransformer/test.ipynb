{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 1\n",
      "64 1\n",
      "64 1\n",
      "number of parameters: 0.15M\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import gym\n",
    "from decision_transformer import DecisionTransformer\n",
    "from dataset.trajectory_dataset import TrajectoryDataset\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "config = {\n",
    "        \"learning_rate\": 2e-4,\n",
    "        \"epochs\": 100,\n",
    "        \"batch_size\": 32,\n",
    "        \"hidden_size\": 64,\n",
    "        \"c_len\": 50,\n",
    "        \"device\": \"auto\",\n",
    "        \"weight_decay\": 1e-4,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "        \"activation_function\": \"relu\",\n",
    "        'dropout': 0.1,\n",
    "        \"warmup_steps\": 10000,\n",
    "        \"num_workers\": 0\n",
    "    }\n",
    "    \n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "c_len = config[\"c_len\"]\n",
    "model = DecisionTransformer(state_dim, action_dim, config[\"hidden_size\"], c_len, 200, True, n_head=1, n_layer=3, n_inner=4*config['hidden_size'],\n",
    "        activation_function=config['activation_function'],\n",
    "        n_positions=1024,\n",
    "        resid_pdrop=config['dropout'],\n",
    "        attn_pdrop=config['dropout'], device=config[\"device\"]).cuda()\n",
    "\n",
    "train_dataset = TrajectoryDataset(c_len, state_dim, action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "tensor([[[[-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09, -1.0000e+09],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09, -1.0000e+09],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09, -1.0000e+09],\n",
      "          ...,\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  5.5217e-03,\n",
      "           -1.3782e-02,  3.0311e-04],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  1.5389e-02,\n",
      "            2.9173e-02,  2.3165e-02],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  1.9076e-03,\n",
      "            5.4983e-03,  1.5087e-02]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "====\n",
      "tensor([[[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0085, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0086, 0.0087, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0084, 0.0084, 0.0085]]]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[[[-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09, -1.0000e+09],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09, -1.0000e+09],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09, -1.0000e+09],\n",
      "          ...,\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -4.3947e-02,\n",
      "           -3.2870e-02,  7.3171e-03],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  1.9108e-02,\n",
      "            2.5715e-02,  3.2182e-02],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  2.9720e-03,\n",
      "            1.1756e-02,  3.9026e-02]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "====\n",
      "tensor([[[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0082, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0085, 0.0086, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0084, 0.0084, 0.0087]]]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[[[-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09, -1.0000e+09],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09, -1.0000e+09],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09, -1.0000e+09],\n",
      "          ...,\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  1.2854e-02,\n",
      "            3.3675e-03,  2.0333e-02],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.8582e-02,\n",
      "           -2.2850e-02, -1.1134e-02],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  1.0486e-02,\n",
      "           -9.7760e-04,  3.4713e-03]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "====\n",
      "tensor([[[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0084, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0082, 0.0082, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0084, 0.0083, 0.0083]]]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "states, actions, returns, dones, timesteps, attn_mask = train_dataset[3]\n",
    "states = states.to(dtype=torch.float).unsqueeze(0).cuda()\n",
    "actions = torch.from_numpy(actions).to(dtype=torch.float).unsqueeze(0).cuda()\n",
    "returns = torch.from_numpy(returns).to(dtype=torch.float).unsqueeze(0).cuda()\n",
    "timesteps = torch.from_numpy(timesteps).to(dtype=torch.long).unsqueeze(0).cuda()\n",
    "attn_mask = torch.from_numpy(attn_mask).unsqueeze(0).cuda()\n",
    "stacked_attn_mask = torch.stack(\n",
    "            (attn_mask, attn_mask, attn_mask), dim=1\n",
    "        ).permute(0, 2, 1).reshape(attn_mask.shape[0], 1, 3*attn_mask.shape[1])\n",
    "attention_mask = stacked_attn_mask.transpose(-1, -2) @ stacked_attn_mask\n",
    "stuff = -1e9 * attention_mask\n",
    "print(attn_mask)\n",
    "action_preds = model(\n",
    "                    states, actions, returns, timesteps=timesteps, attn_mask=attn_mask\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
